
![arogya jpg](https://github.com/user-attachments/assets/11bd1e04-2bf7-4ad1-af46-5ba2fa307da5)


**Demo Video:** [Watch on Google Drive](https://drive.google.com/file/d/1BB1mZT3JOKmFPGYyekpy1WLpaZc3psxi/view?usp=drivesdk)



# ğŸ©º Arogyamitra â€” Offline Clinical AI Platform for Hospitals



**Arogyamitra is a healthcare technology startup building safe, offline AI solutions for hospitals â€” beyond API-calling LLMs.**

Arogyamitra delivers **hospital-grade, on-device AI** that works reliably even without internet connectivity.  
Using **quantized small language models (SLMs)** and **plug-and-play LoRA adapters**, hospitals can instantly add domain-specific AI skills while maintaining privacy, safety, and control.

## ğŸŒŸ Overview

Arogyamitra is **not** an API wrapper â€” it is a fully offline, privacy-first, hospital-grade AI platform designed for real clinical workflows in low-connectivity or air-gapped environments.

## ğŸ“š Table of Contents

- [âœ¨ Key Features](#-key-features)
- [ğŸ§  Core Innovations](#-core-innovations)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ’» Installation](#-installation)
- [ğŸ³ Docker Deployment](#-docker-deployment)
- [ğŸ Vision & Closing](#-vision--closing)

## âœ¨ Key Features

### ğŸ¤– Offline Clinical AI Core
- Fully offline **on-device inference**
- Fine-tuned **Gemma-1B** (quantized to ~322MB)
- CPU-only execution (no GPU required)
- Works in **airplane mode** or complete network isolation
- No external API dependency â†’ zero cloud risk

### ğŸ”Œ LoRA Adapter Marketplace
> *Think of it like an App Store â€” but for AI skills.*

- Plug-and-play **domain-specific LoRA adapters**
- Swap AI expertise without retraining the base model
- Demo adapters include:
  - ğŸ§  Mental Health Companion
  - ğŸ“„ Medical Insurance Guidance
  - ğŸ¥ Care Pathway & Hospital Navigation
  - ğŸ”¬ Clinical Report Analysis

- Developers can upload adapters
- Hospitals buy/download and deploy them **offline**

### ğŸ“Š Datasets Used for Demo LoRA Adapter Fine-Tuning

The following publicly available datasets were used to demonstrate fine-tuning of quantized LoRA adapters:

1. **Mental Health Counseling Conversations** (Kaggle)  
   Curated Q&A from online counseling platforms covering diverse mental health topics  
   [Download from Kaggle](https://www.kaggle.com/datasets/melissamonfared/mental-health-counseling-conversations-k)

2. **RaDialog Instruct Dataset**  
   Image-grounded instruct dataset for chest X-ray radiology tasks  
   [Download from PhysioNet](https://physionet.org/content/radialog-instruct-dataset/1.1.0/)

3. **MIMIC-CXR Dataset**  
   Large-scale chest X-ray dataset with de-identified images and radiology reports  
   [Download from PhysioNet](https://physionet.org/content/mimic-cxr/)

4. **MedQuAD (Medical Question Answering Dataset)**  
   High-quality medical Q&A collection from reliable sources (NIH, MedlinePlus)  
   [Download from HuggingFace](https://huggingface.co/datasets/lavita/MedQuAD)

### ğŸ’¬ Real-Time Doctorâ€“Patient Chat
- Built with **Express + Socket.IO**
- Secure, room-based consultations
- Role-based access:
  - ğŸ‘¤ Patient
  - ğŸ‘¨â€âš•ï¸ Doctor

**Live Features:**
- Join/leave notifications
- Typing indicators
- Chat history sync
- Private AI messages (role-scoped)

### ğŸ§  Dual-Persona AI Safety Engine

#### ğŸ§ Patient AI
- Empathetic, reassuring tone
- Simple, non-technical language
- One question at a time
- âŒ **No diagnosis**
- âŒ **No lab interpretation**
- Always encourages doctor review

#### ğŸ‘¨â€âš•ï¸ Doctor AI
- Clinical-grade analysis
- Full medical terminology
- Abnormal value detection
- Evidence-based reasoning

âœ” Prevents hallucinations and reduces medico-legal risk

### ğŸ“ Medical File Processing

Supported formats:
- **PDF** â€” via `pdf-parse`
- **Word** â€” via `mammoth`
- **Text** â€” UTF-8
- **Images** â€” OCR via **Tesseract + Sharp**

**OCR Enhancement Example:**
```javascript
sharp(image)
  .greyscale()
  .normalize()
  .sharpen();


### ğŸ”¬ Explainable Medical AI (XAI)

All AI outputs include:
- Clinical summary  
- Critical findings  
- Normal range â†’ current value â†’ deviation %  
- Step-by-step reasoning  
- Confidence score  
- Immediate concerns  
- Recommendations  

### ğŸ• Temporal Health Intelligence

- Longitudinal report comparison  
- Trend detection  
- Early warning signals  
- Deterioration / improvement analysis  

### ğŸš¨ Emergency Detection & Escalation

- Keyword detection (chest pain, breathlessness, stroke, seizure, suicide, etc.)

**AI Triage Output (example):**
```json
{
  "level": "CRITICAL | HIGH | MODERATE | LOW",
  "reasoning": "...",
  "urgentAdvice": "..."
}
```

**Automatic escalation:**
- Immediate patient guidance
- Private doctor alerts
- Normal AI flow is paused during emergencies

### ğŸ“‹ Doctor Co-Pilot
- Automatic SOAP note generation
- Uses:
  - Chat history
  - Uploaded reports
  - AI insights
- Saves 10â€“15 minutes per consultation

### ğŸ“· Webcam-Based Vital Monitoring (PPG)
- Uses remote photoplethysmography (rPPG)
- Estimates:
  - Heart rate
  - Breathing rate
  - Stress indicators
- Non-contact, no wearables needed
- Runs inside chat via AI tool calls

## ğŸ§  Core Innovations

1. **Offline-first hospital AI**
2. **Modular LoRA skill system**
3. **Demo fine-tuning on public datasets**
4. **Role-based AI isolation** (patient vs. doctor personas)
5. **Explainable and auditable outputs**
6. **Privacy-by-design architecture**

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        A[Web Browser]
        A1[Doctor Interface]
        A2[Patient Interface]
    end
    
    subgraph "Communication Layer"
        B[Express Server :9000]
        C[Socket.IO Real-time Engine]
        D[PeerJS WebRTC Server]
    end
    
    subgraph "Authentication & Access Control"
        E[Room Validation]
        F[Hash-based Invitations]
        G[Email Verification]
    end
    
    subgraph "AI Processing Engine"
        H[Role-Based AI Router]
        I[Patient AI Persona]
        J[Doctor AI Persona]
        K[ChatGroq LLM<br/>Llama-3.3-70B]
        L[Emergency Detection System]
    end
    
    subgraph "Medical Document Processing"
        M[File Upload Handler<br/>Multer]
        N[Multi-Format Parser]
        N1[PDF Parser]
        N2[Word Parser]
        N3[OCR Engine<br/>Tesseract + Sharp]
        O[Health Metrics Extractor]
        P[XAI Analysis Engine]
        Q[Temporal Intelligence]
    end
    
    subgraph "LoRA Adapter System"
        R[Base Model<br/>Gemma-1B Quantized]
        S[LoRA Adapter Loader]
        T1[Mental Health]
        T2[Medical Insurance]
        T3[Clinical Analysis]
        T4[Care Navigation]
    end
    
    subgraph "Clinical Tools"
        U[SOAP Note Generator]
        V[PPG Vital Monitor]
        W[Longitudinal Tracker]
    end
    
    subgraph "Data Storage"
        X[Room State Manager]
        Y[Message History]
        Z[File Repository]
        AA[Health Metrics Store]
    end
    
    A --> A1
    A --> A2
    A1 --> B
    A2 --> B
    B --> C
    B --> D
    B --> E
    E --> F
    E --> G
    F --> X
    
    C --> H
    H --> I
    H --> J
    I --> K
    J --> K
    H --> L
    L --> K
    
    C --> M
    M --> N
    N --> N1
    N --> N2
    N --> N3
    N --> O
    O --> K
    N --> P
    P --> K
    P --> Q
    Q --> K
    
    K --> R
    R --> S
    S --> T1
    S --> T2
    S --> T3
    S --> T4
    
    H --> U
    H --> V
    H --> W
    U --> K
    
    X --> Y
    X --> Z
    X --> AA
    O --> AA
    
    C --> X
    
    style K fill:#FF6B6B,stroke:#C92A2A,stroke-width:3px,color:#fff
    style R fill:#4ECDC4,stroke:#0A7E7A,stroke-width:3px,color:#fff
    style H fill:#FFE66D,stroke:#D4A017,stroke-width:2px
    style L fill:#FF8B94,stroke:#D32F2F,stroke-width:2px
    style P fill:#95E1D3,stroke:#38A3A5,stroke-width:2px
```

## ğŸ› ï¸ Tech Stack

### Backend
- **Node.js** + **Express** â€” Server framework
- **Socket.IO** â€” Real-time bidirectional communication
- **PeerJS** â€” WebRTC signaling for video calls
- **Multer** â€” File upload middleware

### AI & ML
- **LangChain** + **ChatGroq** â€” LLM orchestration
- **Llama-3.3-70B-Versatile** â€” Production LLM
- **Gemma-1B (Quantized)** â€” Offline inference model
- **LoRA Adapters** â€” Domain-specific skills

### Document Processing
- **pdf-parse** â€” PDF text extraction
- **mammoth** â€” Word document parsing
- **Tesseract.js** â€” OCR engine
- **Sharp** â€” Image preprocessing

### Frontend
- **HTML5/CSS3/JavaScript** â€” Core web technologies
- **Socket.IO Client** â€” Real-time updates
- **PeerJS Client** â€” WebRTC video/audio

## ğŸ’» Installation

### Prerequisites
```bash
- Node.js >= 16.x
- npm or yarn
- Tesseract OCR binary (for image processing)
```

### Setup Steps

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/arogyamitra.git
cd arogyamitra
```

2. **Install dependencies**
```bash
npm install
```

3. **Environment Configuration**
Create a `.env` file:
```env
PORT=9000
GROQ_API_KEY=your_groq_api_key_here
DOCTOR_EMAIL=your_doctor_email@example.com
```

4. **Create required directories**
```bash
mkdir uploads
mkdir public
```

5. **Start the server**
```bash
npm start
```

6. **Access the application**
```
http://localhost:9000
```

## ğŸ³ Docker Deployment

### Using Docker Compose

```yaml
version: '3.8'
services:
  arogyamitra:
    build: .
    ports:
      - "9000:9000"
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
      - DOCTOR_EMAIL=${DOCTOR_EMAIL}
    volumes:
      - ./uploads:/app/uploads
      - ./models:/app/models
    restart: unless-stopped
```

### Build and Run
```bash
docker-compose up -d
```

## ğŸ“¡ API Endpoints

### Room Management
- `POST /api/create-room` â€” Create consultation room (Doctor only)
- `POST /api/validate-room` â€” Validate room access
- `GET /api/doctor-rooms` â€” Get doctor's active rooms

### File Operations
- `POST /upload` â€” Upload medical files with AI analysis

## ğŸ” Security Features

1. **Hash-based Room Invitations** â€” Secure, single-use links
2. **Email Verification** â€” Role-based access control
3. **Role Isolation** â€” Separate AI personas for patient/doctor
4. **Private Messages** â€” Role-scoped AI responses
5. **No Data Leakage** â€” Patient never sees clinical analysis

## ğŸ¯ Usage Flow

### For Doctors:
1. Create room with patient email
2. Share secure invitation link
3. Wait for patient to join
4. Start video consultation (optional)
5. Review AI-analyzed reports
6. Generate SOAP notes
7. End session

### For Patients:
1. Receive invitation link
2. Join room with email verification
3. Upload medical reports
4. Chat with doctor
5. Ask AI (patient-safe responses)
6. Receive prescriptions/advice

## ğŸš€ Roadmap

- [ ] Multi-language support (Hindi, Tamil, Bengali)
- [ ] Offline LoRA adapter marketplace
- [ ] Mobile app (React Native)
- [ ] Integration with HIS/EMR systems
- [ ] Blockchain-based medical records
- [ ] Advanced PPG vitals monitoring

## ğŸ Vision & Closing

Arogyamitra aims to democratize clinical AI for hospitals in low-connectivity regions while maintaining the highest standards of privacy, safety, and explainability. Unlike cloud-based API wrappers, our offline-first architecture ensures:

âœ… Zero data leakage  
âœ… Complete privacy control  
âœ… No vendor lock-in  
âœ… Works in air-gapped environments  
âœ… Modular skill system via LoRA adapters  

**Demo Video:** [Watch on Google Drive](https://drive.google.com/file/d/1BB1mZT3JOKmFPGYyekpy1WLpaZc3psxi/view?usp=drivesdk)

---

**Built with â¤ï¸ for healthcare providers worldwide**

## ğŸ“„ License

MIT License - See LICENSE file for details



---

*Arogyamitra - Bringing AI to healthcare, offline and on-device.*
```
